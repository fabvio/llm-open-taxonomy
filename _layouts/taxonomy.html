---
layout: default
---

{% if site.data.menu and site.paginate and site.paginate_path and paginator.page > 1 %}
  {% include menu.html %}
{% elsif site.paginate and site.paginate_path and paginator.page > 1 %}
  {% include back-link.html %}
{% else %}
  <header class="site-masthead">
    {% include menu.html %}
    <h1>LLM Openness Taxonomy</h1>
  </header>
{% endif %}

<main class="home" id="main" role="main" aria-label="Content">
  <h4>Model Pipeline</h4>
  <img src="/assets/images/components.png" alt="Openness Taxonomy" style="width: 100%; max-width: 800px; margin: 0 auto; display: block;">
  <br>
  <div style="text-align: center; font-style: italic; font-size: medium">Figure 1. Pipeline of the components of model (1) training, (2) evaluation and (3) deployment for typical LLMs.</div>
  <br>

  There are several components involved in the (1) training, (2) evaluation and (3) deployment pipeline to obtain a Large Language Model (LLM).
  Model developers decide whether to make each component of those pipelines <div style="font-style: italic; display: inline;">private</div> or <div style="font-style: italic; display: inline;">public</div>, with varying levels of restrictions for
  the latter. These are summarized in Figure 1, and detailed below.
  <br><br>

  Model training processes can be grouped into three distinct
  stages: <div style="font-style: italic; display: inline;">pre-training</div>, where a model is exposed to large-scale
  datasets composed of trillions of tokens of data, with the
  goal of developing fundamental skills and broad knowledge;
  <div style="font-style: italic; display: inline;">supervised fine-tuning (SFT)</div>, which corrects for data quality issues in pre-training datasets using a smaller amount
  of high-quality data; and  <div style="font-style: italic; display: inline;">alignment</div>, focusing on creating
  application-specific versions of the model by considering
  human preferences. Once trained, models are usually evaluated on openly available evaluation datasets (e.g., MMLU
  by <a href="https://arxiv.org/abs/2009.03300" target="_blank" style="text-decoration: none; color: #4682B4;">Hendrycks et al., 2020</a>) as well as curated benchmarks
  (e.g., HELM by <a href="https://arxiv.org/abs/2211.09110" target="_blank" style="text-decoration: none; color: #4682B4;">Liang et al., 2022</a>). Some models are also
  evaluated on utility-oriented proprietary datasets held internally by developers, potentially by holding out some of
  the SFT/alignment data from the training process <a href="https://arxiv.org/abs/2307.09288" target="_blank" style="text-decoration: none; color: #4682B4;">(Touvron
  et al., 2023a)</a>. On top of utility-based benchmarking, developers sometimes create safety evaluation mechanisms
  to proactively stress-test the outputs of the model (e.g., red
  teaming via adversarial prompts). Finally, at the deployment
  stage, content can be generated by running the inference
  code with the associated model weights.

  <h4>Classifying Openness</h4>
  <img src="/assets/images/openness_scale.png" alt="Openness Scale" style="width: 100%; max-width: 800px; margin: 0 auto; display: block;">
  <br>
  <div style="text-align: center; font-style: italic; font-size: medium">Figure 2. Categorization of the levels of openness of the code and data of each model component.</div>
  <br>
  To categorize the openness of each component, we introduce the scale presented in Figure 2. 
  At the highest level, a <div style="font-weight: bold; display: inline;">fully closed</div> component is not publicly
  accessible in any form. In contrast, a
  <div style="font-weight: bold; display: inline;">semi-open</div> component is publicly accessible but with certain
  limitations on access or use, or it is available in a restricted
  manner, such as through an Application Programming Interface (API). Finally, a <div style="font-weight: bold; display: inline;">fully open</div>
  component is available to the public without any restrictions
  on its use. 
  <br><br>
  Further, the semi-open category
  comprises three subcategories, delineating varied openness
  levels (see Figure 2). Distinctions are made between Code
  (C1-C5) and Data (D1-D5) components, where C5/D5 represents unrestricted availability and C1/D1 denotes complete
  unavailability. For semi-open components, their classification relies on the license of the publicly available code/data.
  <br><br>
  To evaluate the licenses we introduce a point-based system
  where each license gets 1 point (for a total maximum of 5)
  for allowing each of the following: 
  <br>
  <ul>
    <li>can use a component for research purposes (Research)</li>
    <li>can use a component for any commercial purposes (Commercial Purposes)</li>
    <li>can modify a component as desired (with notice) (Modify as Desired)</li>
    <li>can copyright derivative (Copyright Derivative Work)</li>
    <li>publicly shared derivative work can use another license (Other license derivative work)</li>
  </ul>
  <br>
  The total number of points is indicative of a license's restrictiveness. A
  <div style="font-weight: bold; display: inline;">Highly restrictive</div> license scores 0-1 points, aligning with
  openness levels of code C2 and data D3, imposing significant limitations. A <div style="font-weight: bold; display: inline;">Moderately restrictive</div> license, scoring
  2-3 points (code C3 and data D3), allows more flexibility
  but with some limitations. Licenses scoring 4 points are
  <div style="font-weight: bold; display: inline;">Slightly restrictive</div> (code C4 and data D4), offering broader
  usage rights with minimal restrictions. Finally, a <div style="font-weight: bold; display: inline;">Restriction free</div> license scores 5 points, indicating the highest level
  of openness (code C5 and data D5), permitting all forms of
  use, modification, and distribution without constraints.

  <h4>Taxonomy</h4>
  Below is a table with the classification of the components of the model pipeline according to the openness scale presented in Figure 2.
</main>
{% include llm-taxonomy.html %}

